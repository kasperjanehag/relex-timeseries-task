{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "from relex.data_processing import prepare_data_for_modeling\n",
    "from relex.model.definition import define_model\n",
    "from relex.model.training import train_model\n",
    "from relex.model.logging import log_inferred_parameters\n",
    "from relex.model.forcasting import forecast_model\n",
    "from relex.model.visualization import (\n",
    "    plot_forecast,\n",
    "    plot_components_with_forecast,\n",
    ")\n",
    "from relex.data_io import load_data_in_wide_format\n",
    "from relex.model.decomposition import (\n",
    "    decompose_historical_time_series,\n",
    "    decompose_forecast_time_series,\n",
    ")\n",
    "from relex.model.evaluation import evaluate\n",
    "\n",
    "# Configure logger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "sns.set_context(\"notebook\", font_scale=1.0)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Load Data\n",
    "def analyze_item(item_num, merged_df):\n",
    "    print(f\"\\n--- Analyzing Item {item_num} ---\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = prepare_data_for_modeling(item_num, df=merged_df)\n",
    "\n",
    "    item_model = define_model(data[\"train_sales\"], data[\"train_prices\"])\n",
    "    variational_posteriors = train_model(item_model=item_model, data=data, item_num=item_num)\n",
    "\n",
    "    # Draw samples from the variational posterior\n",
    "    parameter_samples = variational_posteriors.sample(50)\n",
    "    log_inferred_parameters(item_model=item_model, parameter_samples=parameter_samples)\n",
    "\n",
    "    forecast_dist, forecast_mean, forecast_scale, forecast_samples = forecast_model(\n",
    "        item_model=item_model, data=data, parameter_samples=parameter_samples)\n",
    "\n",
    "    # Get releveant date indeicies\n",
    "    dates_pd = pd.DatetimeIndex(data[\"dates\"])\n",
    "    forecast_dates = pd.DatetimeIndex(data[\"test_dates\"])\n",
    "\n",
    "    plot_forecast(\n",
    "        dates_pd,\n",
    "        data[\"full_sales\"],\n",
    "        forecast_mean,\n",
    "        forecast_scale,\n",
    "        forecast_samples,\n",
    "        title=f\"Sales Forecast for Item {item_num}\",\n",
    "    )\n",
    "\n",
    "    # Decompose time series\n",
    "    component_means, component_stddevs = decompose_historical_time_series(\n",
    "        item_model, data, parameter_samples\n",
    "    )\n",
    "    forecast_component_means, forecast_component_stddevs = (\n",
    "        decompose_forecast_time_series(item_model, forecast_dist, parameter_samples)\n",
    "    )\n",
    "\n",
    "    # Plot components with forecasts\n",
    "    fig, _ = plot_components_with_forecast(\n",
    "        dates=dates_pd,  # All dates\n",
    "        train_dates=dates_pd[: len(data[\"train_sales\"])],  # Historical dates\n",
    "        forecast_dates=forecast_dates,  # Forecast dates\n",
    "        component_means_dict=component_means,\n",
    "        component_stddevs_dict=component_stddevs,\n",
    "        forecast_component_means=forecast_component_means,  # Use consistent variable name\n",
    "        forecast_component_stddevs=forecast_component_stddevs,  # Use consistent variable name\n",
    "    )\n",
    "\n",
    "    rmse, mape = evaluate(data, forecast_mean, component_means, forecast_component_means)\n",
    "\n",
    "    return {\n",
    "        \"model\": item_model,\n",
    "        \"forecast_mean\": forecast_mean,\n",
    "        \"forecast_scale\": forecast_scale,\n",
    "        \"parameters\": parameter_samples,\n",
    "        \"component_means\": component_means,\n",
    "        \"component_stddevs\": component_stddevs,\n",
    "        \"forecast_component_means\": forecast_component_means,\n",
    "        \"forecast_component_stddevs\": forecast_component_stddevs,\n",
    "        \"metrics\": {\"rmse\": rmse, \"mape\": mape},\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    merged_df = load_data_in_wide_format(\n",
    "        price_data_path=\"../data/average_price.csv\",\n",
    "        sales_data_path=\"../data/category_sales.csv\",\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        f\"item_{item_num}\": analyze_item(item_num, merged_df)\n",
    "        for item_num in range(1, 5)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
