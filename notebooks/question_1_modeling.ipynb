{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "from relex.data_processing import prepare_data_for_modeling\n",
    "from relex.model.definition import define_model\n",
    "from relex.model.training import train_model\n",
    "from relex.model.logging import log_inferred_parameters\n",
    "from relex.model.forcasting import forecast_model\n",
    "from relex.model.visualization import (\n",
    "    plot_forecast,\n",
    "    plot_components_with_forecast,\n",
    ")\n",
    "from relex.data_io import load_data_in_wide_format\n",
    "\n",
    "# Configure logger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "sns.set_context(\"notebook\", font_scale=1.0)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Load Data\n",
    "def analyze_item(item_num, merged_df):\n",
    "    print(f\"\\n--- Analyzing Item {item_num} ---\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = prepare_data_for_modeling(item_num, df=merged_df)\n",
    "\n",
    "    # Build & train the model\n",
    "    item_model = define_model(data[\"train_sales\"], data[\"train_prices\"])\n",
    "    variational_posteriors = train_model(item_model=item_model, data=data, item_num=item_num)\n",
    "\n",
    "    # Draw samples from the variational posterior\n",
    "    parameter_samples = variational_posteriors.sample(50)\n",
    "    log_inferred_parameters(item_model=item_model, parameter_samples=parameter_samples)\n",
    "\n",
    "    forecast_dist, forecast_mean, forecast_scale, forecast_samples = forecast_model(\n",
    "        item_model=item_model, data=data, parameter_samples=parameter_samples)\n",
    "\n",
    "    # Convert dates to pd.DatetimeIndex for easier handling\n",
    "    dates_pd = pd.DatetimeIndex(data[\"dates\"])\n",
    "\n",
    "    # Create forecast dates correctly - weekly frequency\n",
    "    last_train_date = dates_pd[len(data[\"train_sales\"]) - 1]\n",
    "    forecast_dates = pd.date_range(\n",
    "        start=last_train_date + pd.Timedelta(days=7),\n",
    "        periods=data[\"num_forecast_steps\"],\n",
    "        freq=\"W\",\n",
    "    )\n",
    "\n",
    "    # Plot the forecast\n",
    "    fig, ax = plot_forecast(\n",
    "        dates_pd,\n",
    "        data[\"full_sales\"],\n",
    "        forecast_mean,\n",
    "        forecast_scale,\n",
    "        forecast_samples,\n",
    "        title=f\"Sales Forecast for Item {item_num}\",\n",
    "    )\n",
    "\n",
    "    # Decompose the time series into components - only for training data\n",
    "    print(\"Decomposing historical time series into components...\")\n",
    "    component_dists = tfp.sts.decompose_by_component(\n",
    "        item_model,\n",
    "        observed_time_series=data[\"train_sales\"],\n",
    "        parameter_samples=parameter_samples,\n",
    "    )\n",
    "\n",
    "    # Extract component means and standard deviations\n",
    "    component_means = {k.name: c.mean().numpy() for k, c in component_dists.items()}\n",
    "    component_stddevs = {k.name: c.stddev().numpy() for k, c in component_dists.items()}\n",
    "\n",
    "    # Now decompose the forecast into components\n",
    "    print(\"Decomposing forecast into components...\")\n",
    "    forecast_component_dists = tfp.sts.decompose_forecast_by_component(\n",
    "        model=item_model,\n",
    "        forecast_dist=forecast_dist,\n",
    "        parameter_samples=parameter_samples,\n",
    "    )\n",
    "\n",
    "    # Extract forecast component means and standard deviations\n",
    "    component_forecast_means = {}  # Make sure this variable name is used consistently\n",
    "    component_forecast_stddevs = {}\n",
    "\n",
    "    print(\"\\nComponent dimensions:\")\n",
    "    for k, c in forecast_component_dists.items():\n",
    "        mean_val = c.mean().numpy()\n",
    "        std_val = c.stddev().numpy()\n",
    "        print(\n",
    "            f\"Component {k.name}: mean shape {mean_val.shape}, stddev shape {std_val.shape}\"\n",
    "        )\n",
    "\n",
    "        # The forecast components might have an extra dimension at the end\n",
    "        # Extract the appropriate slice based on shape\n",
    "        if mean_val.ndim > 1:\n",
    "            mean_val = mean_val[..., 0]  # Take the first slice of the last dimension\n",
    "        if std_val.ndim > 1:\n",
    "            std_val = std_val[..., 0]\n",
    "\n",
    "        component_forecast_means[k.name] = mean_val  # Use consistent variable name\n",
    "        component_forecast_stddevs[k.name] = std_val  # Use consistent variable name\n",
    "\n",
    "    # Plot components with forecasts\n",
    "    fig, _ = plot_components_with_forecast(\n",
    "        dates=dates_pd,  # All dates\n",
    "        train_dates=dates_pd[: len(data[\"train_sales\"])],  # Historical dates\n",
    "        forecast_dates=forecast_dates,  # Forecast dates\n",
    "        component_means_dict=component_means,\n",
    "        component_stddevs_dict=component_stddevs,\n",
    "        component_forecast_means_dict=component_forecast_means,  # Use consistent variable name\n",
    "        component_forecast_stddevs_dict=component_forecast_stddevs,  # Use consistent variable name\n",
    "    )\n",
    "    plt.suptitle(f\"Component Decomposition for Item {item_num}\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate forecast accuracy metrics\n",
    "    forecast_error = data[\"test_sales\"] - forecast_mean\n",
    "    rmse = np.sqrt(np.mean(forecast_error**2))\n",
    "    mape = np.mean(np.abs(forecast_error / data[\"test_sales\"])) * 100\n",
    "\n",
    "    print(f\"\\nForecast Accuracy Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "    # Calculate component contributions (variance explained)\n",
    "    total_variance = np.var(data[\"train_sales\"])\n",
    "    component_variances = {name: np.var(mean) for name, mean in component_means.items()}\n",
    "    component_percentages = {\n",
    "        name: var / total_variance * 100 for name, var in component_variances.items()\n",
    "    }\n",
    "\n",
    "    print(\"\\nComponent Contribution (% variance explained):\")\n",
    "    for name, percentage in component_percentages.items():\n",
    "        print(f\"{name}: {percentage:.2f}%\")\n",
    "\n",
    "    # Calculate component contributions to forecast\n",
    "    forecast_variance = np.var(forecast_mean)\n",
    "    forecast_component_variances = {\n",
    "        name: np.var(mean)\n",
    "        for name, mean in component_forecast_means.items()  # Use consistent variable name\n",
    "    }\n",
    "    forecast_component_percentages = {\n",
    "        name: var / forecast_variance * 100\n",
    "        for name, var in forecast_component_variances.items()\n",
    "    }\n",
    "\n",
    "    print(\"\\nComponent Contribution to Forecast (% variance explained):\")\n",
    "    for name, percentage in forecast_component_percentages.items():\n",
    "        print(f\"{name}: {percentage:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"model\": item_model,\n",
    "        \"forecast_mean\": forecast_mean,\n",
    "        \"forecast_scale\": forecast_scale,\n",
    "        \"parameters\": parameter_samples,\n",
    "        \"component_means\": component_means,\n",
    "        \"component_stddevs\": component_stddevs,\n",
    "        \"component_forecast_means\": component_forecast_means,  # Use consistent variable name\n",
    "        \"component_forecast_stddevs\": component_forecast_stddevs,  # Use consistent variable name\n",
    "        \"metrics\": {\"rmse\": rmse, \"mape\": mape},\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    merged_df = load_data_in_wide_format(\n",
    "        price_data_path=\"../data/average_price.csv\",\n",
    "        sales_data_path=\"../data/category_sales.csv\",\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        f\"item_{item_num}\": analyze_item(item_num, merged_df)\n",
    "        for item_num in range(1, 5)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
